---
apiVersion: v1
kind: Service
metadata:
  name: llm-d-modelservice
  namespace: llm-d
  labels:
    app.kubernetes.io/name: llm-d-modelservice
spec:
  selector:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: inference-sim
    llm-d.ai/role: decode
  ports:
    - name: http
      port: 8000
      targetPort: 8000
      protocol: TCP
