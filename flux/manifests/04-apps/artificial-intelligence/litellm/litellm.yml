---
model_list:
  # OpenAI models
  - model_name: gpt-5
    litellm_params:
      model: gpt-5
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-5-nano
    litellm_params:
      model: gpt-5-nano
      api_key: os.environ/OPENAI_API_KEY
  - model_name: o3-mini
    litellm_params:
      model: o3-mini
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY

  # OpenAI Embedding models
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY

  # Anthropic models
  - model_name: claude-sonnet-4-5
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: claude-4-5-haiku
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY

  # Local models (OpenAI-compatible endpoint)
  - model_name: llama3.2
    litellm_params:
      model: openai/llama3.2:3b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: gpt-oss
    litellm_params:
      model: openai/gpt-oss:20b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: dolphin3
    litellm_params:
      model: openai/dolphin3:8b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: deepseek-r1
    litellm_params:
      model: openai/deepseek-r1:14b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: qwen3
    litellm_params:
      model: openai/qwen3:8b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE

  # Local embedding models (native Ollama endpoint)
  - model_name: nomic-embed-text
    litellm_params:
      model: ollama/nomic-embed-text
      api_base: os.environ/OLLAMA_API_BASE
      drop_params: true
    model_info:
      mode: embedding

  # llm-d models (Kubernetes-native inference serving with inference-sim)
  # Uses openai/ provider prefix for OpenAI-compatible vLLM endpoint
  - model_name: inference-sim
    litellm_params:
      model: openai/llm-d/inference-sim
      api_base: http://llm-d-modelservice.llm-d.svc.cluster.local:8000/v1

guardrails:
  - guardrail_name: "gibberish-guard"
    litellm_params:
      guardrail: guardrails_ai
      guard_name: "gibberish-guard"
      mode: "post_call"
      guardrails_ai_api_input_format: "llmOutput"
      api_base: os.environ/GUARDRAILS_AI_API_BASE
      default_on: false # Disabled until Guardrails AI is fixed

vector_store_registry:
  - vector_store_name: "pgvector-litellm"
    litellm_params:
      custom_llm_provider: "pg_vector"
      vector_store_id: "09beee6f-ed62-47c6-a161-dea9018a5a40"
      vector_store_description: "PGVector vector store for LiteLLM"
      api_base: "http://vector-store.litellm.svc.cluster.local:8000"
      api_key: os.environ/VECTOR_STORE_API_KEY

mcp_servers:
  gofetch:
    alias: "gofetch"
    url: "http://mcp-gofetch-proxy.mcp-gofetch.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  osv:
    alias: "osv"
    url: "http://mcp-osv-vulnerability-scanner-proxy.mcp-osv.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  mkp:
    alias: "mkp"
    url: "http://mcp-kubernetes-mcp-proxy.mcp-mkp.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  grafana:
    alias: "grafana"
    url: "http://mcp-grafana-mcp-proxy.mcp-grafana.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
    # Forward Grafana auth headers from client
    extra_headers:
      - "X-Grafana-API-Key"
  searxng:
    alias: "searxng"
    url: "http://mcp-searxng-mcp-proxy.mcp-searxng.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  github:
    alias: "github"
    url: "https://api.githubcopilot.com/mcp/"
    transport: "http"
    auth_type: "none"
    # Forward GitHub PAT from client
    extra_headers:
      - "Authorization"
  flux:
    alias: "flux"
    url: "http://mcp-flux-mcp-proxy.mcp-flux.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  deepwiki:
    alias: "deepwiki"
    url: "https://mcp.deepwiki.com/mcp"
    transport: "http"
    auth_type: "none"
  homeassistant:
    alias: "homeassistant"
    url: "https://home.apocrathia.com:8123/api/mcp"
    transport: "http"
    auth_type: "none"
    # Static HA Long-Lived Access Token for initialization
    static_headers:
      Authorization: os.environ/HOMEASSISTANT_TOKEN
    # Allow client to override with their own token
    extra_headers:
      - "Authorization"
