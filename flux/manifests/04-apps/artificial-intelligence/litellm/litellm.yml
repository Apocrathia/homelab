---
model_list:
  # OpenAI models
  - model_name: gpt-5
    litellm_params:
      model: gpt-5
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-5-nano
    litellm_params:
      model: gpt-5-nano
      api_key: os.environ/OPENAI_API_KEY
  - model_name: o3-mini
    litellm_params:
      model: o3-mini
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY

  # OpenAI Embedding models
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY

  # Anthropic models
  - model_name: claude-sonnet-4-5
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: claude-4-5-haiku
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY

  # Local models (OpenAI-compatible endpoint)
  - model_name: llama3.2
    litellm_params:
      model: openai/llama3.2:3b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: gpt-oss
    litellm_params:
      model: openai/gpt-oss:20b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: dolphin3
    litellm_params:
      model: openai/dolphin3:8b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: deepseek-r1
    litellm_params:
      model: openai/deepseek-r1:14b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: qwen3
    litellm_params:
      model: openai/qwen3:14b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE
  - model_name: cogito
    litellm_params:
      model: openai/cogito:14b
      api_base: os.environ/OLLAMA_OPENAI_API_BASE

  # Local embedding models (native Ollama endpoint)
  - model_name: nomic-embed-text
    litellm_params:
      model: ollama/nomic-embed-text
      api_base: os.environ/OLLAMA_API_BASE
      drop_params: true
    model_info:
      mode: embedding

  # llm-d models (Kubernetes-native inference serving with inference-sim)
  # Uses openai/ provider prefix for OpenAI-compatible vLLM endpoint
  - model_name: inference-sim
    litellm_params:
      model: openai/llm-d/inference-sim
      api_base: http://llm-d-modelservice.llm-d.svc.cluster.local:8000/v1

guardrails:
  - guardrail_name: "gibberish-guard"
    litellm_params:
      guardrail: guardrails_ai
      guard_name: "gibberish-guard"
      mode: "post_call"
      guardrails_ai_api_input_format: "llmOutput"
      api_base: os.environ/GUARDRAILS_AI_API_BASE
      default_on: false # Disabled until Guardrails AI is fixed

vector_store_registry:
  - vector_store_name: "pgvector-litellm"
    litellm_params:
      custom_llm_provider: "pg_vector"
      vector_store_id: "09beee6f-ed62-47c6-a161-dea9018a5a40"
      vector_store_description: "PGVector vector store for LiteLLM"
      api_base: "http://vector-store.litellm.svc.cluster.local:8000"
      api_key: os.environ/VECTOR_STORE_API_KEY

mcp_servers:
  gofetch:
    alias: "gofetch"
    url: "http://mcp-gofetch-proxy.mcp-gofetch.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  osv:
    alias: "osv"
    url: "http://mcp-osv-vulnerability-scanner-proxy.mcp-osv.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  mkp:
    alias: "mkp"
    url: "http://mcp-kubernetes-mcp-proxy.mcp-mkp.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  grafana:
    alias: "grafana"
    url: "http://mcp-grafana-mcp-proxy.mcp-grafana.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
    # Forward Grafana auth headers from client
    extra_headers:
      - "X-Grafana-API-Key"
  searxng:
    alias: "searxng"
    url: "http://mcp-searxng-mcp-proxy.mcp-searxng.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  github:
    alias: "github"
    url: "http://mcp-github-mcp-server-proxy.mcp-github.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  flux:
    alias: "flux"
    url: "http://mcp-flux-mcp-proxy.mcp-flux.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  deepwiki:
    alias: "deepwiki"
    url: "https://mcp.deepwiki.com/mcp"
    transport: "http"
    auth_type: "none"
  homeassistant:
    alias: "homeassistant"
    url: "https://home.apocrathia.com:8123/api/mcp"
    transport: "http"
    auth_type: "none"
    # Static HA Long-Lived Access Token for initialization
    static_headers:
      Authorization: os.environ/HOMEASSISTANT_TOKEN
    # Allow client to override with their own token
    extra_headers:
      - "Authorization"
  openzim:
    alias: "openzim"
    url: "http://mcp-openzim-mcp-proxy.mcp-openzim.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  unifi:
    alias: "unifi"
    url: "http://mcp-unifi-network-mcp-proxy.mcp-unifi.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  gitlab:
    alias: "gitlab"
    url: "http://mcp-gitlab-mcp-server-proxy.mcp-gitlab.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  servarr:
    alias: "servarr"
    url: "http://mcp-servarr-mcp-proxy.mcp-servarr.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  plex:
    alias: "plex"
    url: "http://mcp-plex-mcp-server-proxy.mcp-plex.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  truenas:
    alias: "truenas"
    url: "http://mcp-truenas-mcp-server-proxy.mcp-truenas.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  proxmox:
    alias: "proxmox"
    url: "http://mcp-proxmox-mcp-plus-proxy.mcp-proxmox.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  firecrawl:
    alias: "firecrawl"
    url: "http://mcp-firecrawl-mcp-proxy.mcp-firecrawl.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  a2a:
    alias: "a2a"
    url: "http://mcp-a2a-mcp-server-proxy.mcp-a2a.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"
  qdrant:
    alias: "qdrant"
    url: "http://mcp-qdrant-mcp-proxy.mcp-qdrant.svc.cluster.local:8080/mcp"
    transport: "http"
    auth_type: "none"

agent_list:
  - agent_name: "homelab-agent"
    litellm_params:
      custom_llm_provider: "a2a_agent"
      url: "http://kagent-controller.kagent.svc.cluster.local:8083/api/a2a/kagent/homelab-agent"
  - agent_name: "search-agent"
    litellm_params:
      custom_llm_provider: "a2a_agent"
      url: "http://kagent-controller.kagent.svc.cluster.local:8083/api/a2a/kagent/search-agent"
  - agent_name: "knowledge-agent"
    litellm_params:
      custom_llm_provider: "a2a_agent"
      url: "http://kagent-controller.kagent.svc.cluster.local:8083/api/a2a/kagent/knowledge-agent"
